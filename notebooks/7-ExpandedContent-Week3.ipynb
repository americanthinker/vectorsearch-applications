{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b11bcbb-3763-4c0e-bd10-aac9aef50e09",
   "metadata": {},
   "source": [
    "#### Week 3: Building Advanced RAG Applications.  Authored by Chris Sanchez.\n",
    "\n",
    "# Week 3 - Notebook 7 --> Context Enrichment\n",
    "\n",
    "# Background  \n",
    "---\n",
    "The background material for this topic/notebook is covered in the [Week 3 Course Content](https://uplimit.com/course/rag-applications/session/session_clzlsa20a01di197e4tij7vgm/module/module_clzlsa9a702cy1dm671cg0xr0) section titled **Context Enrichment**.  \n",
    "\n",
    "# Overview\n",
    "---\n",
    "The concept of Context Enrichment became popularized with the advent of LLMs that could reason over ever-increasing context window sizes. Prior to 2022 most open-source Reader models were limited to a 512 token context window. From a vector search perspective, adding the Context Enrichment technique to your toolbox allows the best of both worlds, because you can figure out which chunk size works best for your embedding model/reranker combo and then expand the retrieved text chunk with surrounding context so that the Reader LLM has the additional context it needs to answer the user query. Though not the only reason, this technique is partly why setting the chunk overlap parameter to zero (when chunking your text into sentences) is a good call.  \n",
    "\n",
    "This notebook will walk you through the process of creating an `expanded_content` field that you can add to an existing dataset, which can then be indexed onto your Weaviate cluster. \n",
    "- No need to create a new dataset, simpy use a prexisting dataset (i.e. `huberman_minilm_256.parquet`)\n",
    "- Group dataset episodes together by `video_id`.  Performing this step will ensure that all before and after text chunks are all from the same episode and there is no \"bleed-over\" into another episode.\n",
    "- Loop over each set of episode chunks and join pre-, current, and post- chunks together as a single string.  The window size can be set as a parameter.\n",
    "- Join each chunk to the original dataset as an additional `expanded_content` field.\n",
    "- Either index the new dataset on a new collection, or update an existing collection.  The properties file used to create the index schema on Weaviate already includes an `expanded_content` property. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebd912-6b31-475e-86d9-4fac57cfcdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d6c6cc-86a5-46ac-ad15-ddfe21331a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(), override=True)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a9ba7a-2fde-4625-a963-c37335270d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.database.properties_template import properties\n",
    "from src.database.weaviate_interface_v4 import WeaviateWCS\n",
    "from src.preprocessor.preprocessing import FileIO\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rich import print\n",
    "from tqdm import tqdm\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014acbc2-478d-404d-918f-639ec5fd2b76",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "No need to create a new dataset, simply use the data that you already have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649a419-30a9-48bc-b13d-df872af711c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"<Your Local Path>\" #'../data/huberman_minilm-256.parquet'\n",
    "data = FileIO.load_parquet(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d1b3c-b6ca-4c80-9006-838b10890788",
   "metadata": {},
   "source": [
    "### Create Expanded Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f0afd-690f-465c-b34f-e236bdf29ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def groupby_episode(data: list[dict], key_field: str='video_id') -> list[list[dict]]:\n",
    "    '''\n",
    "    Separates entire podcast corpus into individual \n",
    "    lists of discrete episodes.\n",
    "    '''\n",
    "    episodes = []\n",
    "    for _, group in groupby(data, lambda x: x[key_field]):\n",
    "        episode = [chunk for chunk in group]\n",
    "        episodes.append(episode)\n",
    "    return episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f8a51-36c0-4266-98c1-e5720de44dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_expanded_content(data: list[dict] | list[list[str]],\n",
    "                            window_size: int=1,\n",
    "                            num_episodes: int=193,\n",
    "                            key_field: str='video_id'\n",
    "                            ) -> list[list[str]]:\n",
    "    '''\n",
    "    Creates expanded content from original chunks of text, for use with \n",
    "    expanded content retrieval.  Takes in raw data as a list of dictionaries \n",
    "    or accepts a list of chunked episodes already grouped. \n",
    "    \n",
    "    Window size sets the number of chunks before and after the original chunk.  \n",
    "    For example a window_size of 2 will return five joined chunks.  2 chunks \n",
    "    before original chunk, the original, and 2 chunks after the original.  \n",
    "    \n",
    "    Expanded content is grouped by podcast episode, and chunks are assumed \n",
    "    to be kept in order by which they will be joined as metadata in follow-on \n",
    "    processing.\n",
    "    '''\n",
    "    # check if dictionaries or already grouped episodes is being passed in\n",
    "    if isinstance(data[0], dict):\n",
    "        # groupby data into episodes using video_id key\n",
    "        episodes = groupby_episode(data, key_field)\n",
    "        assert len(episodes) == num_episodes, f'Number of grouped episodes does not equal num_episodes ({len(episodes)} != {num_episodes})'\n",
    "\n",
    "        # extract content field and ensure episodes maintain their grouping\n",
    "        chunk_list = [[d['content'] for d in alist] for alist in episodes]\n",
    "        \n",
    "    expanded_contents = []\n",
    "    for episode in tqdm(chunk_list):\n",
    "        episode_container = []\n",
    "        for i, chunk in enumerate(episode):\n",
    "            start = max(0, i-window_size)\n",
    "            end = i+window_size+1\n",
    "            expanded_content = ' '.join(episode[start:end])\n",
    "            episode_container.append(expanded_content)\n",
    "        expanded_contents.append(episode_container)\n",
    "    return expanded_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd792d-e257-455a-998f-e4ae9262891a",
   "metadata": {},
   "source": [
    "# Assignment 3.1 - \n",
    "***\n",
    "#### *Create Expanded Content chunks and join them to existing data*\n",
    "\n",
    "#### INSTRUCTIONS\n",
    "1. Execute the `create_expanded_content` function.  Depending on your chunk size, it is likely best to use the default window size of 1.  Meaning, 1 chunk of text will be added before and after the original text chunk, for a total of three chunks for each `expanded_content` field.\n",
    "2. Assuming you are going to join the data back to the original dataset from which it came, you'll need to flatten out the list of episode into a single list of text chunks.\n",
    "3. Write a function that updates your original dataset with the new expanded content by updating the dataset with an `expanded_content` key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f2d97-56f6-4596-bb53-222c3bb020b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# START YOUR CODE HERE #\n",
    "########################\n",
    "\n",
    "expanded_content = None\n",
    "flattened_content = None\n",
    "\n",
    "# azimuth check to ensure you're heading in the right direction\n",
    "flat_length = len(flattened_content)\n",
    "data_length = len(data)\n",
    "assert flat_length == data_length, 'Mismatch in lengths. Double check how you flattened your expanded_content'\n",
    "\n",
    "def join_expanded_content(data: list[dict],\n",
    "                          flattened_content: list[list[str]],\n",
    "                          new_key: str = 'expanded_content'\n",
    "                          ) -> list[dict]:\n",
    "    '''\n",
    "    Updates data with an expanded_content key.\n",
    "    '''\n",
    "\n",
    "########################\n",
    "# END YOUR CODE HERE #\n",
    "########################\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = join_expanded_content(None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501aadc-1843-4e23-b706-2a54c19677f4",
   "metadata": {},
   "source": [
    "#### After executing the above function, run the following cells as a post-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc86127-1cf9-4f4b-bf59-3b83ef266cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure all expanded content fields are present\n",
    "for d in data:\n",
    "    assert d.get('expanded_content', -1) != -1\n",
    "    \n",
    "#compare your initial result with the following cell\n",
    "print(data[0]['expanded_content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042e44c-2aaa-48fc-af89-776d416a471a",
   "metadata": {},
   "source": [
    "<details> \n",
    "    <summary>\n",
    "        Click to compare your results from the cell above with the following:\n",
    "</summary>  \n",
    "    \n",
    "```\n",
    "\"Welcome to the Huberman Lab guest series, where I and an expert guest discuss science and science-based tools for everyday life. I'm Andrew Huberman, and I'm a professor of neurobiology and ophthalmology at Stanford School of Medicine. Today's episode marks the first in our six-episode series all about sleep. Our expert guest for this series is Dr. Matthew Walker, professor of neuroscience and psychology and the director of the Center for Sleep Science at the University of California, Berkeley. He is also the author of the bestselling book, Why We Sleep. During the course of the six-episode series, for which we release one episode per week, starting with this episode one, we cover essentially all aspects of sleep and provide numerous practical tools to improve your sleep. For instance, we discuss the biology of sleep, including the different sleep stages, as well as why sleep is so important for our mental and physical health. We also talk about how sleep regulates things like emotionality and learning and neuroplasticity, that is your brain's ability to change in response to experience. And we discuss the various things that you can do to improve your sleep. Everything from how to time lighting, temperature, exercise, eating, and the various things that can impact sleep both positively and negatively, such as alcohol, cannabis, and various supplements and drugs that have been shown to improve sleep. We also talk about naps, dreaming and the role of dreams, and lucid dreaming, which is when you dream and you are aware that you are dreaming. In today's episode one, we specifically focus on why sleep is so important and what happens when we do not get enough sleep or enough quality sleep. We also talk about the various sleep stages, and we also talk about a very specific formula that everyone should know for themselves called QQRT, which is an acronym that stands for quality, quantity, regularity, and timing of sleep. Four factors which today you'll learn how to identify specifically for you what your optimal QQRT is, and then to apply that in order to get the best possible night's sleep, which of course equates to the best possible level of focus and alertness throughout your days. Both Dr.\"\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e417972-3a16-4236-b3af-4056c62eefc3",
   "metadata": {},
   "source": [
    "### Index the Data\n",
    "---\n",
    "You have two options here:\n",
    "1. Easy way: Simply index the data on a new Collection.\n",
    "2. Hard way: Read all existing uuids on current Collection and update each object by linking the doc_ids.\n",
    "\n",
    "As mentioned earlier, the `expanded_content` property is already part of the index configuration of properties.  See the last property entry after printing the `properties` variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93deae35-08b2-4eec-b8da-7e6743f83db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9822c-5d7c-4f57-8719-902f65123c65",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---\n",
    "After you've indexed the data you will now have a way to retrieve content on a fine-grained level, and provide your LLM Reader with an expanded context.  You will be able to see this in action when you add `expanded_content` as a `return_property` in your Streamlit UI. ðŸŽ‰  \n",
    "\n",
    "However, the important idea here is how does adding expanded content affect your RAG system performance?  Assuming you completed Notebook 5 you now have the means at your disposal of running an evaluation with the Reader LLM ingesting the `expanded_content` field as context instead of the `content` field. Setting up your own evaluation will be a good exercise in understanding how all of these pieces are put together.  You'll note that the function used to build the user message at run time `generate_prompt_series` as well as the  `create_context_blocks` function have a `content_key` parameter.  You will want to pass in `expanded_content` as an argument here instead of `content`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ea8276-f8b1-4f8f-b76d-25d66d3d09ae",
   "metadata": {},
   "source": [
    "## OPTIONAL: Update an existing Collection\n",
    "---\n",
    "For those interested in doing things the hard way here is some starter code.  No guarantee that this code will work as written, but it gives you the idea of how you would accomplish this task; or just create a new Collection... ðŸ˜€:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81c228-d7d9-4db7-8cf7-5ec4fa326594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get collection object\n",
    "api_key = os.environ['WEAVIATE_API_KEY']\n",
    "endpoint = os.environ['WEAVIATE_ENDPOINT']\n",
    "\n",
    "client = WeaviateWCS(endpoint, api_key)\n",
    "collection = client._client.collections.get('Huberman_minilm_256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fde8c03-0d00-43c5-a837-80b2597c8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step will take a few minutes to read every object id on the Weaviate cluster\n",
    "doc_id_cache = {item.properties['doc_id']:item.uuid for item in tqdm(collection.iterator())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c13cc3-c9bd-4a59-bc1c-a2c79dc93b03",
   "metadata": {},
   "source": [
    "`doc_id_cache` example:\n",
    "```\n",
    "{'-OBCwiPPfEU_8': _WeaviateUUIDInt('018455e9-47ab-41cc-b592-c431fd8df75f'),\n",
    " '-OBCwiPPfEU_4': _WeaviateUUIDInt('03a18709-0334-4f18-9375-4a8a3f162cfb'),\n",
    " '-OBCwiPPfEU_0': _WeaviateUUIDInt('0da24442-3263-46d7-91af-ef2a34d27a9c'),\n",
    " '-OBCwiPPfEU_1': _WeaviateUUIDInt('219354b1-dd2e-46c0-94cb-cdd51f915175'),\n",
    " '-OBCwiPPfEU_6': _WeaviateUUIDInt('27f967f2-3e9c-453d-8d21-378e4e15ffac'),\n",
    " '-OBCwiPPfEU_7': _WeaviateUUIDInt('332a363f-afcf-4fb7-9370-bbded23b8803'),\n",
    " '-OBCwiPPfEU_3': _WeaviateUUIDInt('59c539ac-8f95-4b13-bb6c-1fb323d7e64a'),\n",
    " '-OBCwiPPfEU_2': _WeaviateUUIDInt('746401bd-98c2-4494-ba08-d1b21d9abfc5'),\n",
    " '-OBCwiPPfEU_9': _WeaviateUUIDInt('77a3a7ae-8d77-4ae5-a0cd-705fb4286198'),\n",
    " '-OBCwiPPfEU_5': _WeaviateUUIDInt('803d2756-e3bd-44ef-88e6-43bc700be480')}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539cfe19-6b67-4e5f-8ef2-e5d1de1b43e8",
   "metadata": {},
   "source": [
    "##### Finally you'll want to loop through your dataset, grab the doc_id value and expanded_content value and then update each object on the Weaviate cluster by using the uuid as found on the doc_id_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e252b3e-ddb7-440e-adf5-1121f52d1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because this is not batched, expect this process to run for several minutes\n",
    "for d in tqdm(data):\n",
    "    doc_id = d['doc_id']\n",
    "    expanded_content = d['expanded_content']\n",
    "    uuid = doc_id_cache[doc_id]\n",
    "    collection.data.update(uuid=uuid, properties={'expanded_content': expanded_content})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "rag-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
