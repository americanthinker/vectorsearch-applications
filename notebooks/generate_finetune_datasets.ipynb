{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fd6de0a-8c4a-4a09-8c47-2af452e95cd4",
   "metadata": {},
   "source": [
    "# Query/Context Dataset Generation\n",
    "***\n",
    "\n",
    "This notebook walks students through the process of generating datasets of query/context pairs which can be used for two primary purposes:\n",
    "- Fine-tuning an embedding model\n",
    "- Serve as ground truth for retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7a0b9a-0f63-465f-b238-286433923925",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# from src.evaluation.retrieval_evaluation import QueryContextGenerator\n",
    "# from llama_index.finetuning import EmbeddingQAFinetuneDataset\n",
    "from src.llm.prompt_templates import qa_generation_prompt\n",
    "from src.llm.llm_interface import LLM\n",
    "from src.preprocessor.preprocessing import FileIO\n",
    "from rich import print\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "env = load_dotenv('.env', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171ce89f-f032-4cd4-851c-7d687387d0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Huberman Lab episode summary and episode guest are below:\n",
       "\n",
       "---------------------\n",
       "Summary: <span style=\"font-weight: bold\">{</span>summary<span style=\"font-weight: bold\">}</span>\n",
       "---------------------\n",
       "Guest: <span style=\"font-weight: bold\">{</span>guest<span style=\"font-weight: bold\">}</span>\n",
       "---------------------\n",
       "Given the Summary and Guest of the episode as context use the following randomly selected transcript section of the\n",
       "episode and not prior knowledge, generate questions that can be answered by the transcript section: \n",
       "\n",
       "---------------------\n",
       "Transcript: <span style=\"font-weight: bold\">{</span>transcript<span style=\"font-weight: bold\">}</span>\n",
       "---------------------\n",
       "\n",
       "Your task is to create <span style=\"font-weight: bold\">{</span>num_questions_per_chunk<span style=\"font-weight: bold\">}</span> questions that can only be answered given the previous context and\n",
       "transcript details and no other information. The question should randomly start with How, Why, or What.   \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Huberman Lab episode summary and episode guest are below:\n",
       "\n",
       "---------------------\n",
       "Summary: \u001b[1m{\u001b[0msummary\u001b[1m}\u001b[0m\n",
       "---------------------\n",
       "Guest: \u001b[1m{\u001b[0mguest\u001b[1m}\u001b[0m\n",
       "---------------------\n",
       "Given the Summary and Guest of the episode as context use the following randomly selected transcript section of the\n",
       "episode and not prior knowledge, generate questions that can be answered by the transcript section: \n",
       "\n",
       "---------------------\n",
       "Transcript: \u001b[1m{\u001b[0mtranscript\u001b[1m}\u001b[0m\n",
       "---------------------\n",
       "\n",
       "Your task is to create \u001b[1m{\u001b[0mnum_questions_per_chunk\u001b[1m}\u001b[0m questions that can only be answered given the previous context and\n",
       "transcript details and no other information. The question should randomly start with How, Why, or What.   \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(qa_generation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e71d80-87e2-4fe2-b98b-90ecf863385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(model_name='azure/gpt-35-turbo', \n",
    "          api_key=os.environ['AZURE_OPENAI_API_KEY'],\n",
    "          api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "          api_base=os.environ['AZURE_OPENAI_ENDPOINT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b8b80be-5f90-45a3-810a-34df4e184a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = QueryContextGenerator(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d3f5307-e884-4a19-8512-e8d36526c25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (11602, 13)\n",
      "Memory Usage: 1.15+ MB\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/huberman_minilm-512.parquet'\n",
    "data = FileIO().load_parquet(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c94f26-2b9b-4cb4-9be8-8e8c21d0d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryContextGenerator:\n",
    "    '''\n",
    "    Class designed for the generation of query/context pairs using a\n",
    "    Generative LLM. The LLM is used to generate questions from a given\n",
    "    corpus of text. The query/context pairs can be used to fine-tune \n",
    "    an embedding model using a MultipleNegativesRankingLoss loss function\n",
    "    or can be used to create evaluation datasets for retrieval models.\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 llm: LLM\n",
    "                ):\n",
    "        self.llm = llm\n",
    "\n",
    "    def clean_validate_data(self,\n",
    "                            data: list[dict], \n",
    "                            valid_fields: list[str]=['content', 'summary', 'guest', 'doc_id'],\n",
    "                            total_chars: int=950\n",
    "                            ) -> list[dict]:\n",
    "        '''\n",
    "        Strip original data chunks so they only contain valid_fields.\n",
    "        Remove any chunks less than total_chars in size. Prevents LLM\n",
    "        from asking questions from sparse content. \n",
    "        '''\n",
    "        clean_docs = [{k:v for k,v in d.items() if k in valid_fields} for d in data]\n",
    "        valid_docs = [d for d in clean_docs if len(d['content']) > total_chars]\n",
    "        return valid_docs\n",
    "\n",
    "    def train_val_split(self,\n",
    "                        data: list[dict],\n",
    "                        n_train_questions: int, \n",
    "                        n_val_questions: int, \n",
    "                        n_questions_per_chunk: int=2,\n",
    "                        total_chars: int=950):\n",
    "        '''\n",
    "        Splits corpus into training and validation sets.  Training and \n",
    "        validation samples are randomly selected from the corpus. total_chars\n",
    "        parameter is set based on pre-analysis of average doc length in the \n",
    "        training corpus. \n",
    "        '''\n",
    "        clean_data = self.clean_validate_data(data, total_chars=total_chars)\n",
    "        random.shuffle(clean_data)\n",
    "        train_index = n_train_questions//n_questions_per_chunk\n",
    "        valid_index = n_val_questions//n_questions_per_chunk\n",
    "        end_index = valid_index + train_index\n",
    "        if end_index > len(clean_data):\n",
    "            raise ValueError('Cannot create dataset with desired number of questions, try using a larger dataset')\n",
    "        train_data = clean_data[:train_index]\n",
    "        valid_data = clean_data[train_index:end_index]\n",
    "        print(f'Length Training Data: {len(train_data)}')\n",
    "        print(f'Length Validation Data: {len(valid_data)}')\n",
    "        return train_data, valid_data\n",
    "\n",
    "    def generate_qa_embedding_pairs(\n",
    "                                    self,\n",
    "                                    data: list[dict],\n",
    "                                    generate_prompt_tmpl: str,\n",
    "                                    system_message: str='You are a helpful assistant.',\n",
    "                                    num_questions_per_chunk: int = 2,\n",
    "                                    ) -> dict:\n",
    "        \"\"\"\n",
    "        Generate query/context pairs from a list of documents. The query/context pairs\n",
    "        can be used for fine-tuning an embedding model using a MultipleNegativesRankingLoss\n",
    "        or can be used to create an evaluation dataset for retrieval models.\n",
    "        \"\"\"\n",
    "        queries = {}\n",
    "        relevant_docs = {}\n",
    "        corpus = {chunk['doc_id'] : chunk['content'] for chunk in data}\n",
    "        for chunk in tqdm(data):\n",
    "            summary = chunk['summary']\n",
    "            guest = chunk['guest']\n",
    "            transcript = chunk['content']\n",
    "            doc_id = chunk['doc_id']\n",
    "            assist_message = generate_prompt_tmpl.format(summary=summary, \n",
    "                                                         guest=guest,\n",
    "                                                         transcript=transcript,\n",
    "                                                         num_questions_per_chunk=num_questions_per_chunk)\n",
    "            try:\n",
    "                response = self.llm.chat_completion(system_message, \n",
    "                                                    assist_message, \n",
    "                                                    temperature=1.0, \n",
    "                                                    max_tokens=num_questions_per_chunk*50,\n",
    "                                                    return_raw=False\n",
    "                                                   )\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            result = response.strip().split(\"\\n\")\n",
    "            questions = [\n",
    "                re.sub(r\"^\\d+[\\).\\s]\", \"\", question).strip() for question in result\n",
    "            ]\n",
    "            questions = [question for question in questions if len(question) > 0]\n",
    "\n",
    "            for question in questions:\n",
    "                question_id = str(uuid.uuid4())\n",
    "                queries[question_id] = question\n",
    "                relevant_docs[question_id] = [doc_id]\n",
    "\n",
    "        # construct dataset\n",
    "        return dict(queries=queries, corpus=corpus, relevant_docs=relevant_docs)\n",
    "\n",
    "# def execute_evaluation(dataset: dict, \n",
    "#                        class_name: str, \n",
    "#                        retriever: str,\n",
    "#                        reranker: ReRanker=None,\n",
    "#                        alpha: float=0.5,\n",
    "#                        retrieve_limit: int=100,\n",
    "#                        top_k: int=5,\n",
    "#                        chunk_size: int=256,\n",
    "#                        hnsw_config_keys: list[str]=['maxConnections', 'efConstruction', 'ef'],\n",
    "#                        search_type: Literal['hybrid', 'all']='all',\n",
    "#                        search_properties: list[str]=['content'],\n",
    "#                        display_properties: list[str]=['doc_id', 'content'],\n",
    "#                        dir_outpath: str='./eval_results',\n",
    "#                        include_miss_info: bool=False,\n",
    "#                        user_def_params: dict=None\n",
    "#                        ) -> Union[dict, Tuple[dict, list[dict]]]:\n",
    "#     '''\n",
    "#     Given a dataset, a retriever, and a reranker, evaluate the performance of the retriever and reranker. \n",
    "#     Returns a dict of kw, vector, and hybrid hit rates and mrr scores. If inlude_miss_info is True, will\n",
    "#     also return a list of kw and vector responses and their associated queries that did not return a hit.\n",
    "\n",
    "#     Args:\n",
    "#     -----\n",
    "#     dataset: EmbeddingQAFinetuneDataset\n",
    "#         Dataset to be used for evaluation\n",
    "#     class_name: str\n",
    "#         Name of Class on Weaviate host to be used for retrieval\n",
    "#     retriever: WeaviateClient\n",
    "#         WeaviateClient object to be used for retrieval \n",
    "#     reranker: ReRanker\n",
    "#         ReRanker model to be used for results reranking\n",
    "#     alpha: float=0.5\n",
    "#         Weighting factor for BM25 and Vector search.\n",
    "#         alpha can be any number from 0 to 1, defaulting to 0.5:\n",
    "#             alpha = 0 executes a pure keyword search method (BM25)\n",
    "#             alpha = 0.5 weighs the BM25 and vector methods evenly\n",
    "#             alpha = 1 executes a pure vector search method\n",
    "#     retrieve_limit: int=5\n",
    "#         Number of documents to retrieve from Weaviate host\n",
    "#     top_k: int=5\n",
    "#         Number of top results to evaluate\n",
    "#     chunk_size: int=256\n",
    "#         Number of tokens used to chunk text\n",
    "#     hnsw_config_keys: list[str]=['maxConnections', 'efConstruction', 'ef']\n",
    "#         list of keys to be used for retrieving HNSW Index parameters from Weaviate host\n",
    "#     search_type: Literal['kw', 'vector', 'hybrid', 'all']='all'\n",
    "#         Type of search to be evaluated.  Options are 'kw', 'vector', 'hybrid', or 'all'\n",
    "#     search_properties: list[str]=['content']\n",
    "#         list of properties to be used for search\n",
    "#     display_properties: list[str]=['doc_id', 'content']\n",
    "#         list of properties to be returned from Weaviate host for display in response\n",
    "#     dir_outpath: str='./eval_results'\n",
    "#         Directory path for saving results.  Directory will be created if it does not\n",
    "#         already exist. \n",
    "#     include_miss_info: bool=False\n",
    "#         Option to include queries and their associated search response values\n",
    "#         for queries that are \"total misses\"\n",
    "#     user_def_params : dict=None\n",
    "#         Option for user to pass in a dictionary of user-defined parameters and their values.\n",
    "#         Will be automatically added to the results_dict if correct type is passed.\n",
    "#     '''\n",
    "        \n",
    "#     reranker_name = reranker.model_name if reranker else \"None\"\n",
    "    \n",
    "#     results_dict = {'n':retrieve_limit, \n",
    "#                     'top_k': top_k,\n",
    "#                     'alpha': alpha,\n",
    "#                     'Retriever': retriever.model_name_or_path, \n",
    "#                     'Ranker': reranker_name,\n",
    "#                     'chunk_size': chunk_size,\n",
    "#                     'hybrid_hit_rate':0,\n",
    "#                     'hybrid_mrr': 0,\n",
    "#                     }\n",
    "#     #add extra params to results_dict\n",
    "#     kw_vector_metrics = {\n",
    "#                          'kw_hit_rate': 0,\n",
    "#                          'kw_mrr': 0,\n",
    "#                          'vector_hit_rate': 0,\n",
    "#                          'vector_mrr': 0\n",
    "#                          }\n",
    "#     if search_type == 'all':\n",
    "#         results_dict = {**results_dict, **kw_vector_metrics}\n",
    "#     results_dict['total_questions'] = 0\n",
    "#     results_dict['total_misses'] = 0\n",
    "#     results_dict = add_params(retriever, class_name, results_dict, user_def_params, hnsw_config_keys)\n",
    "        \n",
    "#     start = time.perf_counter()\n",
    "#     miss_info_list = []\n",
    "#     for query_id, q in tqdm(dataset.queries.items(), 'Queries'):\n",
    "#         results_dict['total_questions'] += 1\n",
    "#         hit = False\n",
    "#         #make Keyword, Vector, and Hybrid calls to Weaviate host\n",
    "#         try:\n",
    "#             hybrid_response = retriever.hybrid_search(request=q, class_name=class_name, properties=search_properties, alpha=alpha, limit=retrieve_limit, display_properties=display_properties)  \n",
    "#             if search_type == 'all':\n",
    "#                 kw_response = retriever.keyword_search(request=q, class_name=class_name, properties=search_properties, limit=retrieve_limit, display_properties=display_properties)\n",
    "#                 vector_response = retriever.vector_search(request=q, class_name=class_name, limit=retrieve_limit, display_properties=display_properties)         \n",
    "#             #rerank returned responses if reranker is provided\n",
    "#             if reranker:\n",
    "#                 hybrid_response = reranker.rerank(hybrid_response, q, top_k=top_k)\n",
    "#                 if search_type == 'all':\n",
    "#                     kw_response = reranker.rerank(kw_response, q, top_k=top_k)\n",
    "#                     vector_response = reranker.rerank(vector_response, q, top_k=top_k)\n",
    "                \n",
    "            \n",
    "#             #collect doc_ids to check for document matches (include only results_top_k)\n",
    "#             hybrid_doc_ids = {result['doc_id']:i for i, result in enumerate(hybrid_response[:top_k], 1)}\n",
    "#             if search_type == 'all':\n",
    "#                 kw_doc_ids = {result['doc_id']:i for i, result in enumerate(kw_response[:top_k], 1)}\n",
    "#                 vector_doc_ids = {result['doc_id']:i for i, result in enumerate(vector_response[:top_k], 1)}\n",
    "#             #extract doc_id for scoring purposes\n",
    "#             doc_id = dataset.relevant_docs[query_id][0]\n",
    "     \n",
    "#             #increment hit_rate counters and mrr scores\n",
    "#             if doc_id in hybrid_doc_ids:\n",
    "#                 results_dict['hybrid_hit_rate'] += 1\n",
    "#                 results_dict['hybrid_mrr'] += 1/hybrid_doc_ids[doc_id]\n",
    "#                 hit = True\n",
    "#             if search_type == 'all':\n",
    "#                 if doc_id in kw_doc_ids:\n",
    "#                     results_dict['kw_hit_rate'] += 1\n",
    "#                     results_dict['kw_mrr'] += 1/kw_doc_ids[doc_id]\n",
    "#                     hit = True\n",
    "#                 if doc_id in vector_doc_ids:\n",
    "#                     results_dict['vector_hit_rate'] += 1\n",
    "#                     results_dict['vector_mrr'] += 1/vector_doc_ids[doc_id]\n",
    "#                     hit = True\n",
    "#             # if no hits, let's capture that\n",
    "#             if not hit:\n",
    "#                 results_dict['total_misses'] += 1\n",
    "#                 miss_info = {'query': q, \n",
    "#                              'answer': dataset.corpus[doc_id],\n",
    "#                              'doc_id': doc_id,\n",
    "#                              'hybrid_response': hybrid_response}\n",
    "#                 if search_type == 'all':\n",
    "#                     miss_info = {**miss_info, \n",
    "#                                  'kw_response': kw_response,\n",
    "#                                  'vector_response': vector_response}\n",
    "#                 miss_info_list.append(miss_info)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             continue\n",
    "\n",
    "#     #use raw counts to calculate final scores\n",
    "#     calc_hit_rate_scores(results_dict, search_type=search_type)\n",
    "#     calc_mrr_scores(results_dict, search_type=search_type)\n",
    "    \n",
    "#     end = time.perf_counter() - start\n",
    "#     print(f'Total Processing Time: {round(end/60, 2)} minutes')\n",
    "#     record_results(results_dict, chunk_size, dir_outpath=dir_outpath, as_text=True)\n",
    "    \n",
    "#     if include_miss_info:\n",
    "#         return results_dict, miss_info\n",
    "#     return results_dict\n",
    "\n",
    "# def calc_hit_rate_scores(results_dict: Dict[str, Union[str, int]], \n",
    "#                          search_type: Literal['hybrid', 'all']='all'\n",
    "#                          ) -> None:\n",
    "#     '''\n",
    "#     Helper function to calculate hit rate scores\n",
    "#     '''\n",
    "#     search_type = ['kw', 'vector', 'hybrid'] if search_type == 'all' else [search_type]\n",
    "#     for prefix in search_type:\n",
    "#         results_dict[f'{prefix}_hit_rate'] = round(results_dict[f'{prefix}_hit_rate']/results_dict['total_questions'],2)\n",
    "\n",
    "# def calc_mrr_scores(results_dict: Dict[str, Union[str, int]],\n",
    "#                     search_type: Literal['hybrid', 'all']='all'\n",
    "#                     ) -> None:\n",
    "#     '''\n",
    "#     Helper function to calculate mrr scores\n",
    "#     '''\n",
    "#     search_type = ['kw', 'vector', 'hybrid'] if search_type == 'all' else [search_type]\n",
    "#     for prefix in search_type:\n",
    "#         results_dict[f'{prefix}_mrr'] = round(results_dict[f'{prefix}_mrr']/results_dict['total_questions'],2)\n",
    "\n",
    "# def create_dir(dir_path: str) -> None:\n",
    "#     '''\n",
    "#     Checks if directory exists, and creates new directory\n",
    "#     if it does not exist\n",
    "#     '''\n",
    "#     if not os.path.exists(dir_path):\n",
    "#         os.makedirs(dir_path)\n",
    "\n",
    "# def record_results(results_dict: Dict[str, Union[str, int]], \n",
    "#                    chunk_size: int, \n",
    "#                    dir_outpath: str='./eval_results',\n",
    "#                    as_text: bool=False\n",
    "#                    ) -> None:\n",
    "#     '''\n",
    "#     Write results to output file in either txt or json format\n",
    "\n",
    "#     Args:\n",
    "#     -----\n",
    "#     results_dict: Dict[str, Union[str, int]]\n",
    "#         Dictionary containing results of evaluation\n",
    "#     chunk_size: int\n",
    "#         Size of text chunks in tokens\n",
    "#     dir_outpath: str\n",
    "#         Path to output directory.  Directory only, filename is hardcoded\n",
    "#         as part of this function.\n",
    "#     as_text: bool\n",
    "#         If True, write results as text file.  If False, write as json file.\n",
    "#     '''\n",
    "#     create_dir(dir_outpath)\n",
    "#     time_marker = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "#     ext = 'txt' if as_text else 'json'\n",
    "#     path = os.path.join(dir_outpath, f'retrieval_eval_{chunk_size}_{time_marker}.{ext}')\n",
    "#     if as_text:\n",
    "#         with open(path, 'a') as f:\n",
    "#             f.write(f\"{results_dict}\\n\")\n",
    "#     else: \n",
    "#         with open(path, 'w') as f:\n",
    "#             json.dump(results_dict, f, indent=4)\n",
    "\n",
    "# def add_params(client: WeaviateClient, \n",
    "#                class_name: str, \n",
    "#                results_dict: dict, \n",
    "#                param_options: dict, \n",
    "#                hnsw_config_keys: list[str]\n",
    "#               ) -> dict:\n",
    "#     '''\n",
    "#     Helper function that adds parameters to the results_dict:\n",
    "#     - Adds HNSW Index parameters to results_dict\n",
    "#     - Adds optional user-defined parameters to results_dict\n",
    "#     '''\n",
    "#     hnsw_params = {k:v for k,v in client.show_class_config(class_name)['vectorIndexConfig'].items() if k in hnsw_config_keys}\n",
    "#     if hnsw_params:\n",
    "#         results_dict = {**results_dict, **hnsw_params}\n",
    "#     if param_options and isinstance(param_options, dict):\n",
    "#         results_dict = {**results_dict, **param_options}\n",
    "#     return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c56caf-f0d4-48dc-883f-00955af5ec6f",
   "metadata": {},
   "source": [
    "### Load raw data\n",
    "Load raw data from parquet file.  Raw data should be in the same format as the dataset (corpus) created in [Notebook 1](https://github.com/americanthinker/vectorsearch-applications/blob/main/1-Data_Preprocessing_Week1_COLAB.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc3833d7-9f28-439d-893c-f76731a599b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (26448, 12)\n",
      "Memory Usage: 2.42+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26448"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './data/impact_theory_minilm_256.parquet'\n",
    "data = FileIO().load_parquet(data_path)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c8787b-3c0c-4999-942f-9f8362eb945b",
   "metadata": {},
   "source": [
    "### Data Length Analysis\n",
    "Conduct an analysis of the length of the content chunks.  Can use either raw words or tokens to assess length.  The main point here is to get a sense of the mean length of content chunks in the data and to set the `total_chars` param in the `clean_validate_data` method with an appropriate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "656fdd2d-9057-4f6c-a767-a8070cec3cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>991.729053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>126.344870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>944.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1974.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  26448.000000\n",
       "mean     991.729053\n",
       "std      126.344870\n",
       "min        4.000000\n",
       "25%      944.000000\n",
       "50%     1005.000000\n",
       "75%     1060.000000\n",
       "max     1974.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in this example the mean content length is @ 1,000\n",
    "lengths = [len(d['content']) for d in data]\n",
    "df = pd.DataFrame(lengths)\n",
    "df.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202dbfca-0a73-4756-b7e7-58f5ef6f62e0",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "\n",
    "The `train_val_split` function will clean and validate the raw data as a first step and then split into user defined train/val splits.  \n",
    "- Cleaning simply strips the keys from the data that are not needed for the query/content generation process\n",
    "- Validation consists of ensuring that only content chunks of length > `total_chars` are passed to the LLM (this step prevents the LLM from asking questions from sparse context)\n",
    "\n",
    "Users define the number of training samples and validation samples to generate.  Number of questions per content chunk can also be set to more than 1, however a note of caution:\n",
    "- Setting `num_questions_per_chunk` > 1 saves time (and money) by asking more than one question per content chunk, however, the dataset will be less diverse.  There is also the potential for the model to generate lower quality questions if the content chunk isn't large enough or meaningful enough to generate more than one question from the content.\n",
    "- Retrieval evaluation results from fine-tuning an embedding model with 200-300 training samples showed an uptick of 5-10% points.  Upper bound on retrieval improvement as a funtion of training sample size is yet to be determined (have fun pushing the boundaries! ðŸ‘Š)\n",
    "- A validation data set is not required for seeing improvement from fine tuning.  The addition of a validation dataset, however, allows a user to test the results of fine tuning on an unseen dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4380c60-c0e9-4f35-b576-59adb173bec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Training Data: 10\n",
      "Length Validation Data: 5\n"
     ]
    }
   ],
   "source": [
    "#split data into train/val sets\n",
    "#in this example we are creating a training set of n=10, val set of n=5, and asking the LLM to only ask 1 question per chunk. \n",
    "train, val = generator.train_val_split(data, 10, 5, 1, total_chars=950)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ac9e4-3f6f-4903-88f7-7c397ddf66c6",
   "metadata": {},
   "source": [
    "### Generate QA pairs\n",
    "\n",
    "To generate query/context pairs we need to pass in our cleaned data splits, a question asking generation prompt, and the number of questions per chunk (needs to be same value passed into the `train_val_split` function.\n",
    "The `qa_generation_prompt` is already preconfigured and supplies the LLM with additional context about the Impact Theory show to ensure high quality questions are asked given the additional context.   \n",
    "Print out the prompt to see what is being asked of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "548ee55b-daa5-4ae3-ae8d-c9d67ac8c859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Impact Theory episode summary and episode guest are below:\n",
       "\n",
       "---------------------\n",
       "Summary: <span style=\"font-weight: bold\">{</span>summary<span style=\"font-weight: bold\">}</span>\n",
       "---------------------\n",
       "Guest: <span style=\"font-weight: bold\">{</span>guest<span style=\"font-weight: bold\">}</span>\n",
       "---------------------\n",
       "Given the Summary and Guest of the episode as context use the following randomly selected transcript section \\  \n",
       "of the episode and not prior knowledge, generate questions that can be answered by the transcript section: \n",
       "\n",
       "---------------------\n",
       "Transcript: <span style=\"font-weight: bold\">{</span>transcript<span style=\"font-weight: bold\">}</span>\n",
       "---------------------\n",
       "\n",
       "Your task is to create <span style=\"font-weight: bold\">{</span>num_questions_per_chunk<span style=\"font-weight: bold\">}</span> questions that can only be answered given the previous context and\n",
       "transcript details. The question should randomly start with How, Why, or What.   \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Impact Theory episode summary and episode guest are below:\n",
       "\n",
       "---------------------\n",
       "Summary: \u001b[1m{\u001b[0msummary\u001b[1m}\u001b[0m\n",
       "---------------------\n",
       "Guest: \u001b[1m{\u001b[0mguest\u001b[1m}\u001b[0m\n",
       "---------------------\n",
       "Given the Summary and Guest of the episode as context use the following randomly selected transcript section \\  \n",
       "of the episode and not prior knowledge, generate questions that can be answered by the transcript section: \n",
       "\n",
       "---------------------\n",
       "Transcript: \u001b[1m{\u001b[0mtranscript\u001b[1m}\u001b[0m\n",
       "---------------------\n",
       "\n",
       "Your task is to create \u001b[1m{\u001b[0mnum_questions_per_chunk\u001b[1m}\u001b[0m questions that can only be answered given the previous context and\n",
       "transcript details. The question should randomly start with How, Why, or What.   \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(qa_generation_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb27ebe-15ac-4807-a579-6474dce6d548",
   "metadata": {},
   "source": [
    "The output from this function is a llama_index class `EmbeddingQAFinetuneDataset`, which is a simple wrapper for a series of three dictionaries (`corpus`, `queries`, and `relevant_docs`).  The llama_index class is not absolutely necessary, but it is helpful in making transitions smoother when using the llama_index `SentenceTransformersFinetuneEngine` class for fine-tuning.  It takes roughly 80 seconds to generate 100 query/context pairs so a sample size of 300 takes about 4 minutes (much faster than if you were to do this manually!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a3fd61-44ea-4642-ba5c-b7acbf800e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:13<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "training_set = generator.generate_qa_embedding_pairs(train, qa_generation_prompt, 2)\n",
    "# val_set = generator.generate_qa_embedding_pairs(val, qa_generation_prompt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e6130c7-d4b6-4d75-b63e-acc85ffed3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EmbeddingQAFinetuneDataset has no len, so check length of queries instead\n",
    "len(training_set.queries), len(val_set.queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7be6432-def2-4dcf-8801-1c56d5f09a86",
   "metadata": {},
   "source": [
    "### Dataset Analysis\n",
    "\n",
    "Always a good idea to check the quality of the pairs generated.  Most pairs will be high quality but some will not be, this is a chance for human intervention to adjust the questions manually to ensure the quality remains high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cda268d4-93b2-4ed4-9700-6819cb7a9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_qa_pairs(data: EmbeddingQAFinetuneDataset, print_results: bool=True):\n",
    "    pairs = []\n",
    "    for k, v in data.queries.items():\n",
    "        doc_id = data.relevant_docs[k][0]\n",
    "        context = data.corpus[doc_id]\n",
    "        pairs.append((v, context))\n",
    "    if print_results:\n",
    "        for tup in pairs:\n",
    "            print(f'Question: {tup[0]}\\nContext: {tup[1]}\\n\\n')\n",
    "    return pairs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6141be90-7c11-40f7-b635-c82f80ea394b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How does Peter Attia approach cancer treatment for his patients?\n",
       "Context: Is it one that responds to immunotherapy? Is there like a protocol that you would walk down? No, it would \n",
       "be entirely dependent on what the cancer was. So that gets to kind of step two of my thinking on cancer, which is \n",
       "the unequivocal, unambiguous understanding that your odds for treating cancer go down the more cancer cells you \n",
       "have in your body. So detecting it sooner. In the book, you talk about you, for your patients, you lower the age of\n",
       "colonoscopy. We do everything much more aggressively. So we're doing colonoscopy much earlier, much more \n",
       "frequently. How often would you do a colonoscopy? Oh, it depends on the individual. I mean, in me, I do it every \n",
       "three years. Really? Yeah, and then I do stool-based testing in between. What do you check for in the stool? You're\n",
       "looking for fecal DNA. So you're looking for DNA of the colon cancer, yeah. Interesting. It has its own DNA? What \n",
       "are we looking for? Yeah, you're looking for the DNA that's shedding from a tumor.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How does Peter Attia approach cancer treatment for his patients?\n",
       "Context: Is it one that responds to immunotherapy? Is there like a protocol that you would walk down? No, it would \n",
       "be entirely dependent on what the cancer was. So that gets to kind of step two of my thinking on cancer, which is \n",
       "the unequivocal, unambiguous understanding that your odds for treating cancer go down the more cancer cells you \n",
       "have in your body. So detecting it sooner. In the book, you talk about you, for your patients, you lower the age of\n",
       "colonoscopy. We do everything much more aggressively. So we're doing colonoscopy much earlier, much more \n",
       "frequently. How often would you do a colonoscopy? Oh, it depends on the individual. I mean, in me, I do it every \n",
       "three years. Really? Yeah, and then I do stool-based testing in between. What do you check for in the stool? You're\n",
       "looking for fecal DNA. So you're looking for DNA of the colon cancer, yeah. Interesting. It has its own DNA? What \n",
       "are we looking for? Yeah, you're looking for the DNA that's shedding from a tumor.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What does Peter Attia check for in stool-based testing for colon cancer?\n",
       "Context: Is it one that responds to immunotherapy? Is there like a protocol that you would walk down? No, it would \n",
       "be entirely dependent on what the cancer was. So that gets to kind of step two of my thinking on cancer, which is \n",
       "the unequivocal, unambiguous understanding that your odds for treating cancer go down the more cancer cells you \n",
       "have in your body. So detecting it sooner. In the book, you talk about you, for your patients, you lower the age of\n",
       "colonoscopy. We do everything much more aggressively. So we're doing colonoscopy much earlier, much more \n",
       "frequently. How often would you do a colonoscopy? Oh, it depends on the individual. I mean, in me, I do it every \n",
       "three years. Really? Yeah, and then I do stool-based testing in between. What do you check for in the stool? You're\n",
       "looking for fecal DNA. So you're looking for DNA of the colon cancer, yeah. Interesting. It has its own DNA? What \n",
       "are we looking for? Yeah, you're looking for the DNA that's shedding from a tumor.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What does Peter Attia check for in stool-based testing for colon cancer?\n",
       "Context: Is it one that responds to immunotherapy? Is there like a protocol that you would walk down? No, it would \n",
       "be entirely dependent on what the cancer was. So that gets to kind of step two of my thinking on cancer, which is \n",
       "the unequivocal, unambiguous understanding that your odds for treating cancer go down the more cancer cells you \n",
       "have in your body. So detecting it sooner. In the book, you talk about you, for your patients, you lower the age of\n",
       "colonoscopy. We do everything much more aggressively. So we're doing colonoscopy much earlier, much more \n",
       "frequently. How often would you do a colonoscopy? Oh, it depends on the individual. I mean, in me, I do it every \n",
       "three years. Really? Yeah, and then I do stool-based testing in between. What do you check for in the stool? You're\n",
       "looking for fecal DNA. So you're looking for DNA of the colon cancer, yeah. Interesting. It has its own DNA? What \n",
       "are we looking for? Yeah, you're looking for the DNA that's shedding from a tumor.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How did Jim Kwik's struggles with learning challenges and fear of public speaking ultimately benefit him \n",
       "in his career?\n",
       "Context: Like that's like the master energy control center. So for me, I would always lean into my practices \n",
       "because it forced me to double down. I think there's a gift. I don't know if it's true enough, but it's been my \n",
       "experience where when people go through struggles that there's a gift in this, like whether there's a gift of \n",
       "what's going on right now, true or false, I choose to believe it because then I'll operate from that, from that \n",
       "point of view and that perspective, meaning what's the gift in me having learning challenges and fearful of public \n",
       "speaking while I got really damn good at learning and public speaking because that's all I do now for, for, for a \n",
       "living, right? What was the advantage that came out of this sleep deprivation experiment for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> years now without \n",
       "that much better is I could tell you two things immediately. It forced me to double down on everything I teach \n",
       "because I'm just, I'm just documenting and telling people what I do, right? Otherwise I won't be able to perform at\n",
       "the level that I do. And then number two, it's forced me also to be very selective in the things I say yes to.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How did Jim Kwik's struggles with learning challenges and fear of public speaking ultimately benefit him \n",
       "in his career?\n",
       "Context: Like that's like the master energy control center. So for me, I would always lean into my practices \n",
       "because it forced me to double down. I think there's a gift. I don't know if it's true enough, but it's been my \n",
       "experience where when people go through struggles that there's a gift in this, like whether there's a gift of \n",
       "what's going on right now, true or false, I choose to believe it because then I'll operate from that, from that \n",
       "point of view and that perspective, meaning what's the gift in me having learning challenges and fearful of public \n",
       "speaking while I got really damn good at learning and public speaking because that's all I do now for, for, for a \n",
       "living, right? What was the advantage that came out of this sleep deprivation experiment for \u001b[1;36m10\u001b[0m years now without \n",
       "that much better is I could tell you two things immediately. It forced me to double down on everything I teach \n",
       "because I'm just, I'm just documenting and telling people what I do, right? Otherwise I won't be able to perform at\n",
       "the level that I do. And then number two, it's forced me also to be very selective in the things I say yes to.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What were the two immediate advantages that Jim Kwik gained from his sleep deprivation experiment?\n",
       "Context: Like that's like the master energy control center. So for me, I would always lean into my practices \n",
       "because it forced me to double down. I think there's a gift. I don't know if it's true enough, but it's been my \n",
       "experience where when people go through struggles that there's a gift in this, like whether there's a gift of \n",
       "what's going on right now, true or false, I choose to believe it because then I'll operate from that, from that \n",
       "point of view and that perspective, meaning what's the gift in me having learning challenges and fearful of public \n",
       "speaking while I got really damn good at learning and public speaking because that's all I do now for, for, for a \n",
       "living, right? What was the advantage that came out of this sleep deprivation experiment for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> years now without \n",
       "that much better is I could tell you two things immediately. It forced me to double down on everything I teach \n",
       "because I'm just, I'm just documenting and telling people what I do, right? Otherwise I won't be able to perform at\n",
       "the level that I do. And then number two, it's forced me also to be very selective in the things I say yes to.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What were the two immediate advantages that Jim Kwik gained from his sleep deprivation experiment?\n",
       "Context: Like that's like the master energy control center. So for me, I would always lean into my practices \n",
       "because it forced me to double down. I think there's a gift. I don't know if it's true enough, but it's been my \n",
       "experience where when people go through struggles that there's a gift in this, like whether there's a gift of \n",
       "what's going on right now, true or false, I choose to believe it because then I'll operate from that, from that \n",
       "point of view and that perspective, meaning what's the gift in me having learning challenges and fearful of public \n",
       "speaking while I got really damn good at learning and public speaking because that's all I do now for, for, for a \n",
       "living, right? What was the advantage that came out of this sleep deprivation experiment for \u001b[1;36m10\u001b[0m years now without \n",
       "that much better is I could tell you two things immediately. It forced me to double down on everything I teach \n",
       "because I'm just, I'm just documenting and telling people what I do, right? Otherwise I won't be able to perform at\n",
       "the level that I do. And then number two, it's forced me also to be very selective in the things I say yes to.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How does Kurt Busch describe the balance between professionalism and tenacity in his racing career?\n",
       "Context: There's some team owners or some mechanics or team personnel that are with you, but they have more of a \n",
       "balanced political approach to it, and then there's some that are just like, you know what? Let's let six months go\n",
       "by, and then we'll reevaluate. In racing timelines, that's way too long. You got to move quick, and that's what was\n",
       "a lot of my not balancing the professionalism with my tenacity or talent from behind the wheel. What do you plan to\n",
       "do in the next phase? At some point, I imagine you will say, okay, I'm going to step away from driving. What do you\n",
       "want to see the next phase of your life? Will it be equally competitive? Is there something that you already have \n",
       "on tap that you want to do? I'm sure I'll be competitive. I married a beautiful woman who is competitive in her own\n",
       "rights. My wife, Ashley, plays competitive polo, and she has her horses, her team, and travels, and she has the \n",
       "same thing that I have. It's called helmetitis. You put a helmet on, and you change into a different person.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How does Kurt Busch describe the balance between professionalism and tenacity in his racing career?\n",
       "Context: There's some team owners or some mechanics or team personnel that are with you, but they have more of a \n",
       "balanced political approach to it, and then there's some that are just like, you know what? Let's let six months go\n",
       "by, and then we'll reevaluate. In racing timelines, that's way too long. You got to move quick, and that's what was\n",
       "a lot of my not balancing the professionalism with my tenacity or talent from behind the wheel. What do you plan to\n",
       "do in the next phase? At some point, I imagine you will say, okay, I'm going to step away from driving. What do you\n",
       "want to see the next phase of your life? Will it be equally competitive? Is there something that you already have \n",
       "on tap that you want to do? I'm sure I'll be competitive. I married a beautiful woman who is competitive in her own\n",
       "rights. My wife, Ashley, plays competitive polo, and she has her horses, her team, and travels, and she has the \n",
       "same thing that I have. It's called helmetitis. You put a helmet on, and you change into a different person.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What does Kurt Busch anticipate for the next phase of his life after stepping away from driving?\n",
       "Context: There's some team owners or some mechanics or team personnel that are with you, but they have more of a \n",
       "balanced political approach to it, and then there's some that are just like, you know what? Let's let six months go\n",
       "by, and then we'll reevaluate. In racing timelines, that's way too long. You got to move quick, and that's what was\n",
       "a lot of my not balancing the professionalism with my tenacity or talent from behind the wheel. What do you plan to\n",
       "do in the next phase? At some point, I imagine you will say, okay, I'm going to step away from driving. What do you\n",
       "want to see the next phase of your life? Will it be equally competitive? Is there something that you already have \n",
       "on tap that you want to do? I'm sure I'll be competitive. I married a beautiful woman who is competitive in her own\n",
       "rights. My wife, Ashley, plays competitive polo, and she has her horses, her team, and travels, and she has the \n",
       "same thing that I have. It's called helmetitis. You put a helmet on, and you change into a different person.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What does Kurt Busch anticipate for the next phase of his life after stepping away from driving?\n",
       "Context: There's some team owners or some mechanics or team personnel that are with you, but they have more of a \n",
       "balanced political approach to it, and then there's some that are just like, you know what? Let's let six months go\n",
       "by, and then we'll reevaluate. In racing timelines, that's way too long. You got to move quick, and that's what was\n",
       "a lot of my not balancing the professionalism with my tenacity or talent from behind the wheel. What do you plan to\n",
       "do in the next phase? At some point, I imagine you will say, okay, I'm going to step away from driving. What do you\n",
       "want to see the next phase of your life? Will it be equally competitive? Is there something that you already have \n",
       "on tap that you want to do? I'm sure I'll be competitive. I married a beautiful woman who is competitive in her own\n",
       "rights. My wife, Ashley, plays competitive polo, and she has her horses, her team, and travels, and she has the \n",
       "same thing that I have. It's called helmetitis. You put a helmet on, and you change into a different person.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How does the brain optimize itself and prevent memory leaks?\n",
       "Context: So please remember, no matter what, if you put time, energy, and repetition into something, your brain is \n",
       "going to rewire. Now, you rewire based on repetition because your brain is always trying to be efficient. It \n",
       "represents something like two or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>% of your body mass and yet takes up <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>% of the energy requirements of your body.\n",
       "Your brain is a caloric hog. And since evolutionarily speaking, calories were hard to come by, your brain is \n",
       "constantly trying to do things to optimize itself. Think about a computer that's running hot. It's trying to lower \n",
       "the resource requirements. And if you get what they call memory leaks in a computer, the computer crashes. The same\n",
       "is true of the brain. So evolution has made sure that we don't have these memory leaks, that we close those apps \n",
       "that are running in the background of the mind so that you don't need to use as many resources. One of the ways \n",
       "that it does it is a process called myelination. Myelination is what people mean when they talk about rewiring your\n",
       "brain. It's actually two parts.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How does the brain optimize itself and prevent memory leaks?\n",
       "Context: So please remember, no matter what, if you put time, energy, and repetition into something, your brain is \n",
       "going to rewire. Now, you rewire based on repetition because your brain is always trying to be efficient. It \n",
       "represents something like two or \u001b[1;36m3\u001b[0m% of your body mass and yet takes up \u001b[1;36m25\u001b[0m% of the energy requirements of your body.\n",
       "Your brain is a caloric hog. And since evolutionarily speaking, calories were hard to come by, your brain is \n",
       "constantly trying to do things to optimize itself. Think about a computer that's running hot. It's trying to lower \n",
       "the resource requirements. And if you get what they call memory leaks in a computer, the computer crashes. The same\n",
       "is true of the brain. So evolution has made sure that we don't have these memory leaks, that we close those apps \n",
       "that are running in the background of the mind so that you don't need to use as many resources. One of the ways \n",
       "that it does it is a process called myelination. Myelination is what people mean when they talk about rewiring your\n",
       "brain. It's actually two parts.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What is myelination and how does it contribute to rewiring the brain?\n",
       "Context: So please remember, no matter what, if you put time, energy, and repetition into something, your brain is \n",
       "going to rewire. Now, you rewire based on repetition because your brain is always trying to be efficient. It \n",
       "represents something like two or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>% of your body mass and yet takes up <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>% of the energy requirements of your body.\n",
       "Your brain is a caloric hog. And since evolutionarily speaking, calories were hard to come by, your brain is \n",
       "constantly trying to do things to optimize itself. Think about a computer that's running hot. It's trying to lower \n",
       "the resource requirements. And if you get what they call memory leaks in a computer, the computer crashes. The same\n",
       "is true of the brain. So evolution has made sure that we don't have these memory leaks, that we close those apps \n",
       "that are running in the background of the mind so that you don't need to use as many resources. One of the ways \n",
       "that it does it is a process called myelination. Myelination is what people mean when they talk about rewiring your\n",
       "brain. It's actually two parts.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What is myelination and how does it contribute to rewiring the brain?\n",
       "Context: So please remember, no matter what, if you put time, energy, and repetition into something, your brain is \n",
       "going to rewire. Now, you rewire based on repetition because your brain is always trying to be efficient. It \n",
       "represents something like two or \u001b[1;36m3\u001b[0m% of your body mass and yet takes up \u001b[1;36m25\u001b[0m% of the energy requirements of your body.\n",
       "Your brain is a caloric hog. And since evolutionarily speaking, calories were hard to come by, your brain is \n",
       "constantly trying to do things to optimize itself. Think about a computer that's running hot. It's trying to lower \n",
       "the resource requirements. And if you get what they call memory leaks in a computer, the computer crashes. The same\n",
       "is true of the brain. So evolution has made sure that we don't have these memory leaks, that we close those apps \n",
       "that are running in the background of the mind so that you don't need to use as many resources. One of the ways \n",
       "that it does it is a process called myelination. Myelination is what people mean when they talk about rewiring your\n",
       "brain. It's actually two parts.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How does Vanessa Van Edwards describe touch as a communication tool?\n",
       "Context: But if you really have someone<span style=\"color: #808000; text-decoration-color: #808000\">...</span> Why least favorite? Because in this world, if we're six feet apart, \n",
       "right? It's really hard to cross that space boundary. And also some people aren't comfortable with touch. So I \n",
       "reserve that one if you're only like, I really need to get their attention. Touch is like the nuclear weapon, or \n",
       "maybe plutonium is the right word. It's the plutonium of communication. It can be used to create nuclear power or \n",
       "an atomic bomb. I don't think we talked about this in the last time they were together, but I went out on a \n",
       "business evening with a woman who touched so much that I was almost laughing to myself. And I<span style=\"color: #808000; text-decoration-color: #808000\">...</span> That's so awkward.\n",
       "No, I know. And it actually wasn't awkward. And what made it so interesting was how hyper aware of it I was and \n",
       "that it still worked. And I was like, how is this possible? Like<span style=\"color: #808000; text-decoration-color: #808000\">...</span> It was working. Yeah. Like forearm, hand. Oh my\n",
       "God. Laughing, shoulder. I was like, what is happening right now? I felt like I was at a magic show.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How does Vanessa Van Edwards describe touch as a communication tool?\n",
       "Context: But if you really have someone\u001b[33m...\u001b[0m Why least favorite? Because in this world, if we're six feet apart, \n",
       "right? It's really hard to cross that space boundary. And also some people aren't comfortable with touch. So I \n",
       "reserve that one if you're only like, I really need to get their attention. Touch is like the nuclear weapon, or \n",
       "maybe plutonium is the right word. It's the plutonium of communication. It can be used to create nuclear power or \n",
       "an atomic bomb. I don't think we talked about this in the last time they were together, but I went out on a \n",
       "business evening with a woman who touched so much that I was almost laughing to myself. And I\u001b[33m...\u001b[0m That's so awkward.\n",
       "No, I know. And it actually wasn't awkward. And what made it so interesting was how hyper aware of it I was and \n",
       "that it still worked. And I was like, how is this possible? Like\u001b[33m...\u001b[0m It was working. Yeah. Like forearm, hand. Oh my\n",
       "God. Laughing, shoulder. I was like, what is happening right now? I felt like I was at a magic show.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: Why did the excessive touching from the woman on the business evening still work despite being hyper \n",
       "aware of it?\n",
       "Context: But if you really have someone<span style=\"color: #808000; text-decoration-color: #808000\">...</span> Why least favorite? Because in this world, if we're six feet apart, \n",
       "right? It's really hard to cross that space boundary. And also some people aren't comfortable with touch. So I \n",
       "reserve that one if you're only like, I really need to get their attention. Touch is like the nuclear weapon, or \n",
       "maybe plutonium is the right word. It's the plutonium of communication. It can be used to create nuclear power or \n",
       "an atomic bomb. I don't think we talked about this in the last time they were together, but I went out on a \n",
       "business evening with a woman who touched so much that I was almost laughing to myself. And I<span style=\"color: #808000; text-decoration-color: #808000\">...</span> That's so awkward.\n",
       "No, I know. And it actually wasn't awkward. And what made it so interesting was how hyper aware of it I was and \n",
       "that it still worked. And I was like, how is this possible? Like<span style=\"color: #808000; text-decoration-color: #808000\">...</span> It was working. Yeah. Like forearm, hand. Oh my\n",
       "God. Laughing, shoulder. I was like, what is happening right now? I felt like I was at a magic show.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: Why did the excessive touching from the woman on the business evening still work despite being hyper \n",
       "aware of it?\n",
       "Context: But if you really have someone\u001b[33m...\u001b[0m Why least favorite? Because in this world, if we're six feet apart, \n",
       "right? It's really hard to cross that space boundary. And also some people aren't comfortable with touch. So I \n",
       "reserve that one if you're only like, I really need to get their attention. Touch is like the nuclear weapon, or \n",
       "maybe plutonium is the right word. It's the plutonium of communication. It can be used to create nuclear power or \n",
       "an atomic bomb. I don't think we talked about this in the last time they were together, but I went out on a \n",
       "business evening with a woman who touched so much that I was almost laughing to myself. And I\u001b[33m...\u001b[0m That's so awkward.\n",
       "No, I know. And it actually wasn't awkward. And what made it so interesting was how hyper aware of it I was and \n",
       "that it still worked. And I was like, how is this possible? Like\u001b[33m...\u001b[0m It was working. Yeah. Like forearm, hand. Oh my\n",
       "God. Laughing, shoulder. I was like, what is happening right now? I felt like I was at a magic show.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How does Susan David explain the role of emotions in our lives and why they are important?\n",
       "Context: This is basically your body doing its job, which is that your emotions evolved to help you to ward off \n",
       "danger, to judge, to criticize, to understand, to pick apart. So when you have these difficult thoughts, emotions, \n",
       "and stories, that's often your body, your psychology doing its job, which is basically trying to help you to be a \n",
       "coherent being in the world. And I'll give you an example of what I mean by this. When I wake up in the morning and\n",
       "I hear my baby cry, my story, which is that is my child that is crying that needs me, is what helps me to tune in \n",
       "that sound relative to the washing machine that's going on in the background. So as human beings, what we do is we \n",
       "take in all these stimuli, we take in all this stuff that's going on in the environment, and we make sense of it. \n",
       "And making sense of these stories, even if they make sense in a way that doesn't serve us, is sense-making. So we \n",
       "all do this. What starts to happen is that we could have grown up with a story that might be I'm unlovable.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How does Susan David explain the role of emotions in our lives and why they are important?\n",
       "Context: This is basically your body doing its job, which is that your emotions evolved to help you to ward off \n",
       "danger, to judge, to criticize, to understand, to pick apart. So when you have these difficult thoughts, emotions, \n",
       "and stories, that's often your body, your psychology doing its job, which is basically trying to help you to be a \n",
       "coherent being in the world. And I'll give you an example of what I mean by this. When I wake up in the morning and\n",
       "I hear my baby cry, my story, which is that is my child that is crying that needs me, is what helps me to tune in \n",
       "that sound relative to the washing machine that's going on in the background. So as human beings, what we do is we \n",
       "take in all these stimuli, we take in all this stuff that's going on in the environment, and we make sense of it. \n",
       "And making sense of these stories, even if they make sense in a way that doesn't serve us, is sense-making. So we \n",
       "all do this. What starts to happen is that we could have grown up with a story that might be I'm unlovable.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What example does Susan David provide to illustrate how our internal narratives help us make sense of the\n",
       "world around us?\n",
       "Context: This is basically your body doing its job, which is that your emotions evolved to help you to ward off \n",
       "danger, to judge, to criticize, to understand, to pick apart. So when you have these difficult thoughts, emotions, \n",
       "and stories, that's often your body, your psychology doing its job, which is basically trying to help you to be a \n",
       "coherent being in the world. And I'll give you an example of what I mean by this. When I wake up in the morning and\n",
       "I hear my baby cry, my story, which is that is my child that is crying that needs me, is what helps me to tune in \n",
       "that sound relative to the washing machine that's going on in the background. So as human beings, what we do is we \n",
       "take in all these stimuli, we take in all this stuff that's going on in the environment, and we make sense of it. \n",
       "And making sense of these stories, even if they make sense in a way that doesn't serve us, is sense-making. So we \n",
       "all do this. What starts to happen is that we could have grown up with a story that might be I'm unlovable.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What example does Susan David provide to illustrate how our internal narratives help us make sense of the\n",
       "world around us?\n",
       "Context: This is basically your body doing its job, which is that your emotions evolved to help you to ward off \n",
       "danger, to judge, to criticize, to understand, to pick apart. So when you have these difficult thoughts, emotions, \n",
       "and stories, that's often your body, your psychology doing its job, which is basically trying to help you to be a \n",
       "coherent being in the world. And I'll give you an example of what I mean by this. When I wake up in the morning and\n",
       "I hear my baby cry, my story, which is that is my child that is crying that needs me, is what helps me to tune in \n",
       "that sound relative to the washing machine that's going on in the background. So as human beings, what we do is we \n",
       "take in all these stimuli, we take in all this stuff that's going on in the environment, and we make sense of it. \n",
       "And making sense of these stories, even if they make sense in a way that doesn't serve us, is sense-making. So we \n",
       "all do this. What starts to happen is that we could have grown up with a story that might be I'm unlovable.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How does Taylor Wilson believe that discovering one's passion is different for everyone?\n",
       "Context: But unlike me, he instilled this point I don't think has discovered what he really wants to use that \n",
       "aptitude for. I was lucky. I found what I wanted to do when I was <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> years old. I don't think most people who are \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span> or even <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> have discovered that yet. But I was just, and I think every day, like I am so lucky to have the\n",
       "parents I had to have the resources I had and to discover that and have that spark when I was <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> years old. It's \n",
       "just about, you know, finding something that you really enjoy whether you're <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> or, you know, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>, right? It happens\n",
       "at different points for everyone. And what do you, do people ask you about, like, how do I find my passion or how \n",
       "do I develop a passion at all? Yeah, I mean, it's hard to say for me. People ask me, you know, how did I become, \n",
       "you know, interested in nuclear science? And it's hard to pinpoint, you know, one specific thing where it's like, I\n",
       "read that or I talked to that person and I knew.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How does Taylor Wilson believe that discovering one's passion is different for everyone?\n",
       "Context: But unlike me, he instilled this point I don't think has discovered what he really wants to use that \n",
       "aptitude for. I was lucky. I found what I wanted to do when I was \u001b[1;36m10\u001b[0m years old. I don't think most people who are \n",
       "\u001b[1;36m25\u001b[0m or even \u001b[1;36m30\u001b[0m or \u001b[1;36m35\u001b[0m have discovered that yet. But I was just, and I think every day, like I am so lucky to have the\n",
       "parents I had to have the resources I had and to discover that and have that spark when I was \u001b[1;36m10\u001b[0m years old. It's \n",
       "just about, you know, finding something that you really enjoy whether you're \u001b[1;36m10\u001b[0m or, you know, \u001b[1;36m40\u001b[0m, right? It happens\n",
       "at different points for everyone. And what do you, do people ask you about, like, how do I find my passion or how \n",
       "do I develop a passion at all? Yeah, I mean, it's hard to say for me. People ask me, you know, how did I become, \n",
       "you know, interested in nuclear science? And it's hard to pinpoint, you know, one specific thing where it's like, I\n",
       "read that or I talked to that person and I knew.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What does Taylor Wilson find challenging when people ask him about how he became interested in nuclear \n",
       "science?\n",
       "Context: But unlike me, he instilled this point I don't think has discovered what he really wants to use that \n",
       "aptitude for. I was lucky. I found what I wanted to do when I was <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> years old. I don't think most people who are \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span> or even <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> or <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span> have discovered that yet. But I was just, and I think every day, like I am so lucky to have the\n",
       "parents I had to have the resources I had and to discover that and have that spark when I was <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> years old. It's \n",
       "just about, you know, finding something that you really enjoy whether you're <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> or, you know, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>, right? It happens\n",
       "at different points for everyone. And what do you, do people ask you about, like, how do I find my passion or how \n",
       "do I develop a passion at all? Yeah, I mean, it's hard to say for me. People ask me, you know, how did I become, \n",
       "you know, interested in nuclear science? And it's hard to pinpoint, you know, one specific thing where it's like, I\n",
       "read that or I talked to that person and I knew.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What does Taylor Wilson find challenging when people ask him about how he became interested in nuclear \n",
       "science?\n",
       "Context: But unlike me, he instilled this point I don't think has discovered what he really wants to use that \n",
       "aptitude for. I was lucky. I found what I wanted to do when I was \u001b[1;36m10\u001b[0m years old. I don't think most people who are \n",
       "\u001b[1;36m25\u001b[0m or even \u001b[1;36m30\u001b[0m or \u001b[1;36m35\u001b[0m have discovered that yet. But I was just, and I think every day, like I am so lucky to have the\n",
       "parents I had to have the resources I had and to discover that and have that spark when I was \u001b[1;36m10\u001b[0m years old. It's \n",
       "just about, you know, finding something that you really enjoy whether you're \u001b[1;36m10\u001b[0m or, you know, \u001b[1;36m40\u001b[0m, right? It happens\n",
       "at different points for everyone. And what do you, do people ask you about, like, how do I find my passion or how \n",
       "do I develop a passion at all? Yeah, I mean, it's hard to say for me. People ask me, you know, how did I become, \n",
       "you know, interested in nuclear science? And it's hard to pinpoint, you know, one specific thing where it's like, I\n",
       "read that or I talked to that person and I knew.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How does Evan Puschak choose the topics for his Nerdwriter videos?\n",
       "Context: You've done such a good job of taking a subject, like Rihanna's work, work, work, work, work song, like \n",
       "you've got a whole fucking show about that song. Tom Bilyeu I love that video. I love making that video. Tom Bilyeu\n",
       "How is this happening? He made a show, he spent a week on this song and it's really interesting. Tom Bilyeu \n",
       "Hardcore week. Tom Bilyeu How did you train yourself to go deep like that? I think when you write a lot, it makes \n",
       "it a little bit easier to compose a story. That part of my brain and mind is still primed for taking information \n",
       "and composing it into something that is persuasive and like a story. Every week or whenever I come up with \n",
       "something for the nerd writer, it's usually a combination of some kind of introspective thought process that I want\n",
       "to talk about and something from the world that I've consumed that I think is interesting and I like to talk about \n",
       "it and it's like, oh there's a good interaction between those two, let's see what I can do there.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How does Evan Puschak choose the topics for his Nerdwriter videos?\n",
       "Context: You've done such a good job of taking a subject, like Rihanna's work, work, work, work, work song, like \n",
       "you've got a whole fucking show about that song. Tom Bilyeu I love that video. I love making that video. Tom Bilyeu\n",
       "How is this happening? He made a show, he spent a week on this song and it's really interesting. Tom Bilyeu \n",
       "Hardcore week. Tom Bilyeu How did you train yourself to go deep like that? I think when you write a lot, it makes \n",
       "it a little bit easier to compose a story. That part of my brain and mind is still primed for taking information \n",
       "and composing it into something that is persuasive and like a story. Every week or whenever I come up with \n",
       "something for the nerd writer, it's usually a combination of some kind of introspective thought process that I want\n",
       "to talk about and something from the world that I've consumed that I think is interesting and I like to talk about \n",
       "it and it's like, oh there's a good interaction between those two, let's see what I can do there.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: Why does Evan Puschak believe that writing a lot makes it easier to compose a persuasive story?\n",
       "Context: You've done such a good job of taking a subject, like Rihanna's work, work, work, work, work song, like \n",
       "you've got a whole fucking show about that song. Tom Bilyeu I love that video. I love making that video. Tom Bilyeu\n",
       "How is this happening? He made a show, he spent a week on this song and it's really interesting. Tom Bilyeu \n",
       "Hardcore week. Tom Bilyeu How did you train yourself to go deep like that? I think when you write a lot, it makes \n",
       "it a little bit easier to compose a story. That part of my brain and mind is still primed for taking information \n",
       "and composing it into something that is persuasive and like a story. Every week or whenever I come up with \n",
       "something for the nerd writer, it's usually a combination of some kind of introspective thought process that I want\n",
       "to talk about and something from the world that I've consumed that I think is interesting and I like to talk about \n",
       "it and it's like, oh there's a good interaction between those two, let's see what I can do there.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: Why does Evan Puschak believe that writing a lot makes it easier to compose a persuasive story?\n",
       "Context: You've done such a good job of taking a subject, like Rihanna's work, work, work, work, work song, like \n",
       "you've got a whole fucking show about that song. Tom Bilyeu I love that video. I love making that video. Tom Bilyeu\n",
       "How is this happening? He made a show, he spent a week on this song and it's really interesting. Tom Bilyeu \n",
       "Hardcore week. Tom Bilyeu How did you train yourself to go deep like that? I think when you write a lot, it makes \n",
       "it a little bit easier to compose a story. That part of my brain and mind is still primed for taking information \n",
       "and composing it into something that is persuasive and like a story. Every week or whenever I come up with \n",
       "something for the nerd writer, it's usually a combination of some kind of introspective thought process that I want\n",
       "to talk about and something from the world that I've consumed that I think is interesting and I like to talk about \n",
       "it and it's like, oh there's a good interaction between those two, let's see what I can do there.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How did the mice in the study gain weight and body fat despite eating the same amount of calories?\n",
       "Context: Those researchers at the Wiseman Institute who understand about what's, you know, the bacteria and mice, \n",
       "they took bacteria samples, fecal samples, which fecal transplantation is like one of the hottest things on the \n",
       "street as well. It's super weird, but it is. But they take they took these fecal samples from folks who had a \n",
       "bacteria cascade associated with obesity and implanted it into lean mice. And they took another set of fecal \n",
       "samples from human subjects who had a bacteria cascade associated with leanness and implanted that into lean mice. \n",
       "Those mice stayed lean. The mice who received the implants from the folks with the bacteria cascade associated with\n",
       "obesity, those mice became insulin resistant. They gained weight and gained body fat, not because of calories, not \n",
       "because they changed what they were eating because of the bacteria. These principles supersede any of the ideas \n",
       "that we carry about just managing calories. If you just get into a caloric deficit because the mice are already \n",
       "eating the same thing, yet they're gaining weight.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How did the mice in the study gain weight and body fat despite eating the same amount of calories?\n",
       "Context: Those researchers at the Wiseman Institute who understand about what's, you know, the bacteria and mice, \n",
       "they took bacteria samples, fecal samples, which fecal transplantation is like one of the hottest things on the \n",
       "street as well. It's super weird, but it is. But they take they took these fecal samples from folks who had a \n",
       "bacteria cascade associated with obesity and implanted it into lean mice. And they took another set of fecal \n",
       "samples from human subjects who had a bacteria cascade associated with leanness and implanted that into lean mice. \n",
       "Those mice stayed lean. The mice who received the implants from the folks with the bacteria cascade associated with\n",
       "obesity, those mice became insulin resistant. They gained weight and gained body fat, not because of calories, not \n",
       "because they changed what they were eating because of the bacteria. These principles supersede any of the ideas \n",
       "that we carry about just managing calories. If you just get into a caloric deficit because the mice are already \n",
       "eating the same thing, yet they're gaining weight.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What did the researchers find when they implanted fecal samples from individuals with a bacteria cascade \n",
       "associated with obesity into lean mice?\n",
       "Context: Those researchers at the Wiseman Institute who understand about what's, you know, the bacteria and mice, \n",
       "they took bacteria samples, fecal samples, which fecal transplantation is like one of the hottest things on the \n",
       "street as well. It's super weird, but it is. But they take they took these fecal samples from folks who had a \n",
       "bacteria cascade associated with obesity and implanted it into lean mice. And they took another set of fecal \n",
       "samples from human subjects who had a bacteria cascade associated with leanness and implanted that into lean mice. \n",
       "Those mice stayed lean. The mice who received the implants from the folks with the bacteria cascade associated with\n",
       "obesity, those mice became insulin resistant. They gained weight and gained body fat, not because of calories, not \n",
       "because they changed what they were eating because of the bacteria. These principles supersede any of the ideas \n",
       "that we carry about just managing calories. If you just get into a caloric deficit because the mice are already \n",
       "eating the same thing, yet they're gaining weight.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What did the researchers find when they implanted fecal samples from individuals with a bacteria cascade \n",
       "associated with obesity into lean mice?\n",
       "Context: Those researchers at the Wiseman Institute who understand about what's, you know, the bacteria and mice, \n",
       "they took bacteria samples, fecal samples, which fecal transplantation is like one of the hottest things on the \n",
       "street as well. It's super weird, but it is. But they take they took these fecal samples from folks who had a \n",
       "bacteria cascade associated with obesity and implanted it into lean mice. And they took another set of fecal \n",
       "samples from human subjects who had a bacteria cascade associated with leanness and implanted that into lean mice. \n",
       "Those mice stayed lean. The mice who received the implants from the folks with the bacteria cascade associated with\n",
       "obesity, those mice became insulin resistant. They gained weight and gained body fat, not because of calories, not \n",
       "because they changed what they were eating because of the bacteria. These principles supersede any of the ideas \n",
       "that we carry about just managing calories. If you just get into a caloric deficit because the mice are already \n",
       "eating the same thing, yet they're gaining weight.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How does Bjorn Lomborg emphasize the importance of prioritizing solutions based on cost-effectiveness and\n",
       "impact?\n",
       "Context: We should have good jobs for everyone. And we should have organic apples for everyone and community \n",
       "gardens and the whole thing. And you're sort of like, really? Yes, of course. I would love this world where we had \n",
       "everything to everyone. But clearly if you're promising everything to everyone, you have no priorities. You're \n",
       "literally not giving any direction. You're just saying all good things in apple pie. But why is that bad? So that \n",
       "sounds amazing. And I think part of people's hangup is what's the problem? Like that sounds awesome. Yes, let's do \n",
       "it. And Bjorn, there are so many people in the world. There's so much wealth. Like, come on, come on. Can't Elon \n",
       "Musk solve these problems by himself? So I can put it to you in a way I love, which is just numbers. So if you try \n",
       "to cost how much this is going to cost, it'll probably cost an additional <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> to $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> trillion. To give you a sense \n",
       "of proportion right now, the global tax intake of all governments in the world is $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> trillion.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How does Bjorn Lomborg emphasize the importance of prioritizing solutions based on cost-effectiveness and\n",
       "impact?\n",
       "Context: We should have good jobs for everyone. And we should have organic apples for everyone and community \n",
       "gardens and the whole thing. And you're sort of like, really? Yes, of course. I would love this world where we had \n",
       "everything to everyone. But clearly if you're promising everything to everyone, you have no priorities. You're \n",
       "literally not giving any direction. You're just saying all good things in apple pie. But why is that bad? So that \n",
       "sounds amazing. And I think part of people's hangup is what's the problem? Like that sounds awesome. Yes, let's do \n",
       "it. And Bjorn, there are so many people in the world. There's so much wealth. Like, come on, come on. Can't Elon \n",
       "Musk solve these problems by himself? So I can put it to you in a way I love, which is just numbers. So if you try \n",
       "to cost how much this is going to cost, it'll probably cost an additional \u001b[1;36m10\u001b[0m to $\u001b[1;36m15\u001b[0m trillion. To give you a sense \n",
       "of proportion right now, the global tax intake of all governments in the world is $\u001b[1;36m15\u001b[0m trillion.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What is the estimated additional cost of providing everything to everyone, according to Bjorn Lomborg?\n",
       "Context: We should have good jobs for everyone. And we should have organic apples for everyone and community \n",
       "gardens and the whole thing. And you're sort of like, really? Yes, of course. I would love this world where we had \n",
       "everything to everyone. But clearly if you're promising everything to everyone, you have no priorities. You're \n",
       "literally not giving any direction. You're just saying all good things in apple pie. But why is that bad? So that \n",
       "sounds amazing. And I think part of people's hangup is what's the problem? Like that sounds awesome. Yes, let's do \n",
       "it. And Bjorn, there are so many people in the world. There's so much wealth. Like, come on, come on. Can't Elon \n",
       "Musk solve these problems by himself? So I can put it to you in a way I love, which is just numbers. So if you try \n",
       "to cost how much this is going to cost, it'll probably cost an additional <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> to $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> trillion. To give you a sense \n",
       "of proportion right now, the global tax intake of all governments in the world is $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> trillion.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What is the estimated additional cost of providing everything to everyone, according to Bjorn Lomborg?\n",
       "Context: We should have good jobs for everyone. And we should have organic apples for everyone and community \n",
       "gardens and the whole thing. And you're sort of like, really? Yes, of course. I would love this world where we had \n",
       "everything to everyone. But clearly if you're promising everything to everyone, you have no priorities. You're \n",
       "literally not giving any direction. You're just saying all good things in apple pie. But why is that bad? So that \n",
       "sounds amazing. And I think part of people's hangup is what's the problem? Like that sounds awesome. Yes, let's do \n",
       "it. And Bjorn, there are so many people in the world. There's so much wealth. Like, come on, come on. Can't Elon \n",
       "Musk solve these problems by himself? So I can put it to you in a way I love, which is just numbers. So if you try \n",
       "to cost how much this is going to cost, it'll probably cost an additional \u001b[1;36m10\u001b[0m to $\u001b[1;36m15\u001b[0m trillion. To give you a sense \n",
       "of proportion right now, the global tax intake of all governments in the world is $\u001b[1;36m15\u001b[0m trillion.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs = show_qa_pairs(training_set, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62170665-3b89-49ef-a266-ab24a86ab43c",
   "metadata": {},
   "source": [
    "### Save to Disk  \n",
    "Save to disk using your own filepaths, below is an example using the length of the sets as part of the filepath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "192d9bb8-8535-4d1e-9229-f93cffb368e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set.save_json('./data/training_data_10.json')\n",
    "# val_set.save_json('./data/validation_data_5.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vsa",
   "language": "python",
   "name": "vsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
